- Configuration under consideration: 
  + full emulation (soft qemu, tcg accelerated) with e1000 emulated network card (network frontend) and and a TAP network backend
  + example of corresponding command: 
    ~qemu-system-x86_64 --accel tcg -m 1g -drive file=tantap.qcow2 -netdev tap,id=mynet0,ifname=tap0,script=no,downscript=no -device e1000,netdev=mynet0,mac=52:55:00:d1:55:01~

* Guest to Host network communication : MMIO management


- Question: What happens when the guest want to output a network packet ?

- MMIO: [[https://en.wikipedia.org/wiki/Memory-mapped_I%2FO]]

- Initialisation
  When the device is initialised it declares a MMIO region which is a special
  Memory Region with callbacks associated for ~read~ and ~write~ operation.

  + For e1000 emulated card this is found here: [[https://github.com/qemu/qemu/blob/v4.2.0/hw/net/e1000.c#L1626-L1642]]
  + The MMIO region is built with this options: [[https://github.com/qemu/qemu/blob/v4.2.0/hw/net/e1000.c#L1342-L1350]]
  + ~e1000_mmio_write~ will be responsible to send the network packet to its associated peer (here the tap backend)
    - following some calls, e1000 ends up calling ~qemu_send_packet~, the generic function to transfer data between peers (here frontend -> backend): [[https://github.com/qemu/qemu/blob/v4.2.0/hw/net/e1000.c#L552]]

- Runtime: how/when the ~read/write~ callbacks are actually called ?
  + that's easy to answer tracing the callers: ~read/write~ callbacks are called by ~memory_dispatch_read/write~ and ~io_readx/io_writex~ in ~cputlb.c~
    which are called by the ~read/store_helper~ in the same file. 

- Now the fun part, who's calling the helper functions
  + enter the TCG magic ...
  + for instance An ARM guest can be emulated in an i386 machines
    Qemu needs to offer various guest/host combination (arm, i386, 32 bits, 64 bits).
    If the gurest can be almost anything the host is determined by the machine qemu is runnning on.
  + Qemu translates the guest instructions to host understandable instructions in 2 phases:
    - first it translates the guest instruction into instructions of an intermediate instruction set: TCG (Tiny Code Generation)
    - second it translates the TCG instruction into instruction executable by the host
    Réf: [[https://github.com/qemu/qemu/blob/v4.2.0/docs/devel/tcg.rst]]
    - translation occurs in the emulated CPU routine. 
      an emulated CPU will (almost) continuously -- [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cpu-exec.c#L715]]
      + get the next sets of instruction to translate and translate it to TCG -- [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/translate-all.c#L1734]]
      + then translate it to the target host instruction sets -- [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/translate-all.c#L1757]]
      + and execute it --  [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cpu-exec.c#L731]]
  + First phase: Guest to TCG -- (actually depends on the guest implementation) [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/translate-all.c#L1734]]
    - instructions are translated by block of instructions:  ~Translation Block (tb)~. Each tb is
      translated one after the another.
    - a ~Tb~ in qemu stores some some meta
      data about the translated instructions (e.g the program counter of the
      current block, the address of the next instruction of the next Tb [e.g to
      jump directly to the next Tb code]) -- [[https://github.com/qemu/qemu/blob/v4.2.0/include/exec/exec-all.h#L366-L433]]
    - there's a cache mecanism that caches Tbs -- [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cpu-exec.c#L403-L410]]
    - guest instructions are translated one after another.
      + depends on the guest arch: e.g for i386 -- [[https://github.com/qemu/qemu/blob/v4.2.0/target/i386/translate.c#L4486]]
        - e.g for ~inc~ instruction 
          + [[https://en.wikipedia.org/wiki/X86_instruction_listings]]
          + [[https://github.com/qemu/qemu/blob/v4.2.0/target/i386/translate.c#L4773-L4776]]
        - One interesting aspect is that for memory access TCG uses load/store instructions
          + e.g for inc if the operant is a memory address it is detected and special load instruction is generated (instead of a move)
            + instruction for loading the operand (address in this case) is generated here: [[https://github.com/qemu/qemu/blob/v4.2.0/target/i386/translate.c#L1413]]
            + instruction for storing the operand (address in this case) is generated here: [[https://github.com/qemu/qemu/blob/v4.2.0/target/i386/translate.c#L439]]
  + Second phase: TCG to Host -- [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg.c#L4013]]
    - ~tcg_gen_code~ go through all the TCG instructions -- [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg.c#L4131-L4138]]
    - But now we have special ld/st instruction when memory is accessed.
      this code is specific to the host arch. For i386: [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L2255]]
      for ld/st instruction -- [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L2527-L2538]]
      opcode are macro generated by: [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg-opc.h#L204-L211]]
    - For load/store opcode, qemu relies on a tlb to do guest to host address translation and proceed with the operations
      + e.g for ld instruction: [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L2122-L2130]]
      + the host address from the TLB are generated: [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L1699]]
      + to handle cache misses (at the execution time (not now)) qemu generates a conditional jump: [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L1759-L1761]]
    - After all the TCG instructions of the Tb are translated, Qemu generates all the slow path blocks (needed in case of cache miss)
      + here -- [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg.c#L4209]]
      + for i386/ld op: [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L1810]]
      + and here ... is the magic ... it generate a call to a c helper function: [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L1850]]
        - ld/store helper calls ~io_readx~/~io_writex~  if the ~tlb_addr~ is flagged as an MMIO region: e.g [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cputlb.c#L1715-L1718]]
  + Now the final magic principle: load/store from/to MMIO regions always lead to a TLB cache miss. How?
    - The TLB is initially empty.
    - In the load/store slow path, ~load_helper~ / ~store_helper~ insert an
      entry in the TLB: [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cputlb.c#L1682-L1691]]
      + [[~tlb_fill~]](https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cputlb.c#L895-L912) (generic) calls [~x86_cpu_tlb_fill~](https://github.com/qemu/qemu/blob/v4.2.0/target/i386/excp_helper.c#L676-L702) which calls [~handle_mmu_fault~](https://github.com/qemu/qemu/blob/v4.2.0/target/i386/excp_helper.c#L349-L673) (x86-specific)
      + ~handle_mmu_fault~ first finds the physical address associated to the virtual address of the memory access while checking access rights at the same time, then calls [~tlb_set_page_with_attrs~](https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cputlb.c#L695-L870) (generic), which:
        + finds the memory region backing the physical address: [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cputlb.c#L732-L733]]
        + for an MMIO region, tags with ~TLB_MMIO~ the virtual address which will figure in the TLB entry: [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cputlb.c#L782-L785]]
        + after applying some cache replacement strategy, sets the TLB entry: [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cputlb.c#L867-L868]]
    - So this TLB entry is filled with the ~TLB_MMIO~ flag set on the relevant address(es) field(s) (~addr_read~ or ~addr_write~ depending on the memory region properties and the MMU protections set)
      + Note that in ~load_helper~ / ~store_helper~, ~tlb_addr~ is the ~addr_read~ / ~addr_write~ field of the TLB entry (~addr_code~ is only used for instruction fetches)
    - On a TLB lookup, the generated code checks flags in the relevant virtual address field of the entry (~addr_read~ or ~addr_write~) and produces a miss (that is jumps to the slow path) if any flag (eg ~TLB_MMIO~) is set: [[https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L1748-L1759]]


* Host to Guest network communication: interruptions

- e1000 receive routine
  + a incoming packet on the TAP interface is seen by the main-loop
  + The TAP device has registered a callback when such event occur : ~tap.c:tap_send~
  + ~tap_send~ (after some indirection) call the ~receive~ method of the network frontend (the ~e1000~ emulated NIC)
    -> ~e1000.c:e1000_receive_iov~
  + the network card has now the packet and uses DMA to write it somewhere in RAM
    - calls ~pci_dma_write~ -- [[https://github.com/qemu/qemu/blob/v4.2.0/hw/net/e1000.c#L968]]
    - This function eventually write in RAM the incoming packet: -- [[https://github.com/qemu/qemu/blob/v4.2.0/exec.c#L3132-L3135]]
      (au passage cela va invalider tous les TB qui utiliserait les pages concernés.)
    - ~e1000~ sets an interruption -- [[https://github.com/qemu/qemu/blob/v4.2.0/hw/net/e1000.c#L1013]]
    - the interruption flows until reaching the CPU ( though pci and i8259 PIC)
      + interruptions is passed between chips using ~irq.c:qemu_set_irq~ (it calls the recorded handler of a chip)
      + called by the generic function ~cpu_interrupt~ which call the specific ~cpu_interrupt_handler~ (there's one per accelerator and thus one for tcg)
      + for tcg ~cpu_interrupt_handler~ is  [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/tcg-all.c#L37-L59]]
        this sets the share variable ~cpu->interrupt_request~.

- CPU hardware interruption in QEMU
  + in between two TB executions the CPU check the interruption status (~cpu->interrupt_request~) -- [[https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cpu-exec.c#L715]]
  + NOTE: does that means the first vCore will handle the interruption ?
  + cpu interruption routine is deferred to a specific harware (e.g x86) -- [[https://github.com/qemu/qemu/blob/v4.2.0/target/i386/cpu.c#L7061]]
    + which filter the interruption source (e.g hardware) -- [[https://github.com/qemu/qemu/blob/v4.2.0/target/i386/seg_helper.c#L1357-L1365]]
    + finally look up on the Interruption Table Descriptor to find the (kernel) interruption handler to call -- [[[[https://github.com/qemu/qemu/blob/v4.2.0/target/i386/seg_helper.c#L872-L879]]]]
    + TODO: understand how/when the packet is actually read by the guest driver (when the interruption handler is called ?)
  
